# -*- coding: utf-8 -*-
"""Session 7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c_71HH7MEHIrnZEIaDEhuU8HElYG7IiW

# Uber and Lyft
"""

import pandas
df = pandas.read_csv("uber_lyft_fares.csv")

# Summary statistics for 'Fare'
print(df['Fare'].describe())

# Plotting the histogram of ride fares
import matplotlib.pyplot as plt
import seaborn as sns


# Histogram of price
sns.histplot(df['Fare'])
plt.title("Histogram of Ride Fares")
plt.xlabel("Fare Price")
plt.ylabel("Frequency")
plt.show()

# Histogram with vertical mean line
sns.histplot(df['Fare'])
plt.axvline(df['Fare'].mean(), color='red', linestyle='dashed', linewidth=2, label='Mean Price')
plt.title("Histogram of Ride Fares with Mean Line")
plt.xlabel("Fare Price")
plt.ylabel("Frequency")
plt.legend()
plt.show()

# Histogram of Uber fares
sns.histplot(df[df['Company'] == 'Uber']['Fare'])
plt.axvline(df[df['Company'] == 'Uber']['Fare'].mean(), color='red', linestyle='dashed', linewidth=2, label='Mean Uber Price')
plt.title("Histogram of Uber Ride Fares with Mean Line")
plt.xlabel("Fare Price")
plt.ylabel("Frequency")
plt.legend()
plt.show()

# Histogram of Lyft fares
sns.histplot(df[df['Company'] == 'Lyft']['Fare'])
plt.axvline(df[df['Company'] == 'Lyft']['Fare'].mean(), color='red', linestyle='dashed', linewidth=2, label='Mean Lyft Price')
plt.title("Histogram of Lyft Ride Fares with Mean Line")
plt.xlabel("Fare Price")
plt.ylabel("Frequency")
plt.legend()
plt.show()

"""As you can see, they seem very similar and it is not easy to detect if there is any difference in prices they charge.

In order to formally test if there is any difference in fare prices, we use the notion of T-test. But remeber that, we first need an F test to comare the variances
"""

price_uber = df[df['Company'] == "Uber"]['Fare']
price_lyft = df[df['Company'] == "Lyft"]['Fare']

from scipy import stats

# F-test
f_stat, f_p_value = stats.levene(price_uber, price_lyft)
print("p-value for the F-test:", f_p_value)

"""Recall that the Null Hypothesis for the F-test is that the variances are equal.

Since the p-value of this test is greater than 0.05, we cannot reject the Null. Therefore, we perform the t-test assuming unequal variances.
"""

# t-test
t_stat, t_p_value = stats.ttest_ind(price_uber, price_lyft, equal_var=True)
print("p-value for the t-test:", t_p_value)

"""# Ad Spend - Scatter Plot"""

import pandas
df = pandas.read_csv("ad_spend.csv")

print(df[['ad_spend', 'visits1']].corr())

print(df[['ad_spend', 'visits2']].corr())

print(df[['ad_spend', 'visits3']].corr())

import seaborn as sns
import matplotlib.pyplot as plt

# Scatterplot for Visits1

sns.scatterplot(x='ad_spend', y='visits1', data=df)
plt.title('Ad Spend vs Website 1 Visits')
plt.xlabel('Ad Spend ($)')
plt.ylabel('Website Visits')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))

# Scatter for Visits1

sns.scatterplot(x='ad_spend', y='visits1', data=df, label = 'Website 1')

# Scatter for Visits2 - overlay
sns.scatterplot(x='ad_spend', y='visits2', data=df, label = 'Website 2')

# Scatter for Visits3 - overlay
sns.scatterplot(x='ad_spend', y='visits3', data=df, label = 'Website 3')

plt.title('Comparison of Slopes: Same Correlation, Different Trajectory')
plt.xlabel('Ad Spend ($)')
plt.ylabel('Website Visits')
plt.legend()
plt.grid(True)
plt.show()

"""# Ad Spend - Regression Analysis"""

import seaborn as sns
import matplotlib.pyplot as plt

# Scatterplot for Visits1 with bold red regression line
# Here we use lmplot instead of scatterplot function since it can automatically add that linear line of regression for us
sns.lmplot(
    x='ad_spend',
    y='visits1',
    data=df,
    line_kws={'color': 'Red', 'linewidth': 3}  # Red line, bold width
)

plt.title('Ad Spend vs Website 1 Visits')
plt.xlabel('Ad Spend ($)')
plt.ylabel('Website Visits')
plt.show()

import statsmodels.formula.api as smf

model = smf.ols('visits1 ~ ad_spend', data=df).fit()
print(model.summary())

import statsmodels.formula.api as smf

model = smf.ols('visits2 ~ ad_spend', data=df).fit()
print(model.summary())

import statsmodels.formula.api as smf

model = smf.ols('visits3 ~ ad_spend', data=df).fit()
print(model.summary())

"""# Wage Gap - Regression"""

import pandas as pd
data = pd.read_csv("salary.csv")

import statsmodels.formula.api as smf

model = smf.ols('Salary ~ Gender', data=data).fit()
print(model.summary())

import statsmodels.formula.api as smf

model = smf.ols('Salary ~ Gender + Experience', data=data).fit()
print(model.summary())

import statsmodels.formula.api as smf

model = smf.ols('Salary ~ Gender + Experience + Age', data=data).fit()
print(model.summary())

import statsmodels.formula.api as smf

model = smf.ols('Salary ~ Gender + Experience + Age + Education', data=data).fit()
print(model.summary())

#determining which education level has been used as the baseline
print(data['Education'].unique())

"""# Cross Tabs"""

# The case of Coffee Consumption and Joining loyalty program
import numpy as np
from scipy.stats import chi2_contingency

# Actual Observed Crosstab (from the black numbers in table)
observed = np.array([
    [35, 120],   # High Consumption
    [77, 301],   # Medium Consumption
    [14, 53]     # Low Consumption
])

# Run Chi-Square test
chi2, p, dof, expected = chi2_contingency(observed)


print("P-value:", p)
print("expected", expected)